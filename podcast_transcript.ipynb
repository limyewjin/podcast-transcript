{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1IA1CyDAIhmMCzN3xigEE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limyewjin/podcast-transcript/blob/main/podcast_transcript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic script for using the OpenAI Whisper model to transcribe an audio file.\n",
        "\n",
        "The output can be passed onto other scripts in [github repository](https://github.com/limyewjin/podcast-transcript) to clean up and provide summaries."
      ],
      "metadata": {
        "id": "tU9vuDz_MSUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "cm_OHS5_NQd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose which model to use by uncommenting\n",
        "#model_name = \"tiny.en\"\n",
        "#model_name = \"base.en\"\n",
        "#model_name = \"small.en\"\n",
        "#model_name = \"medium.en\"\n",
        "model_name = \"large-v2\"\n",
        "\n",
        "output_folder = \"transcriptions\"\n",
        "language = \"english\"\n",
        "export_timestamp_data = True # Outputs timestamp data at the word level if True"
      ],
      "metadata": {
        "id": "LXlOG2HhNSR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation (run once or after changing `model_name`)"
      ],
      "metadata": {
        "id": "9lWxQykzM4rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX06OrLFLzBb"
      },
      "outputs": [],
      "source": [
        "# Required third party packages: whisper\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "import whisper\n",
        "import io\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "\n",
        "model = whisper.load_model(modelName)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "fI8zWigLOvTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using model: {modelName}\")\n",
        "file_path = input(\"Path to file being transcribed: \")\n",
        "file_path = file_path.strip(\"\\\"\")\n",
        "if not os.path.exists(file_path):\n",
        "\tprint(\"Error getting file\")\n",
        "\texit()\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "\tos.makedirs(output_folder)\n",
        "\tprint(f\"Created output folder {output_folder}.\\n\")\n",
        "\n",
        "# From Whisper API:\n",
        "# Optional text to provide as a prompt for the first window. This can be used to provide, or\n",
        "# \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n",
        "# to make it more likely to predict those word correctly.\n",
        "prompt = input(\"Optional text prompt: \").strip()\n",
        "if prompt == \"\": prompt = None\n",
        "\n",
        "# Get filename stem using pathlib (filename without extension)\n",
        "filename_stem = pathlib.Path(file_path).stem\n",
        "\n",
        "result_fileName = f\"{filename_stem}.txt\"\n",
        "json_fileName = f\"{filename_stem}.json\"\n",
        "\n",
        "start = time.time()\n",
        "result = model.transcribe(audio=filePath, language=language, word_timestamps=word_timestamps, verbose=verbose, prompt=prompt)\n",
        "end = time.time()\n",
        "elapsed = float(end - start)\n",
        "\n",
        "# Save transcription text to file\n",
        "print(\"\\nWriting transcription to file...\")\n",
        "with open(os.path.join(output_folder, result_fileName), \"w\", encoding=\"utf-8\") as f:\n",
        "\tf.write(result[\"text\"])\n",
        "\n",
        "# Save the segments data to json file\n",
        "if export_timestamp_data == True:\n",
        "\tprint(\"\\nWriting segment data to file...\")\n",
        "\twith open(os.path.join(outputFolder, json_fileName), \"w\", encoding=\"utf-8\") as f:\n",
        "\t\tsegments_data = result[\"segments\"]\n",
        "\t\tjson.dump(segments_data, f, indent=4)\n",
        "\n",
        "elapsedMinutes = str(round(elapsed/60, 2))\n",
        "print(f\"\\nElapsed time With {modelName} Model: {elapsedMinutes} minutes\")"
      ],
      "metadata": {
        "id": "aw0XCMP4PMwH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}