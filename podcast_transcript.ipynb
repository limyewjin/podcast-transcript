{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPiW2rGmXexcY55LkykHTFn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limyewjin/podcast-transcript/blob/main/podcast_transcript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic script for using the OpenAI Whisper model to transcribe an audio file.\n",
        "\n",
        "The output can be passed onto other scripts in [github repository](https://github.com/limyewjin/podcast-transcript) to clean up and provide summaries."
      ],
      "metadata": {
        "id": "tU9vuDz_MSUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters"
      ],
      "metadata": {
        "id": "cm_OHS5_NQd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose which model to use by uncommenting\n",
        "#model_name = \"tiny.en\"\n",
        "#model_name = \"base.en\"\n",
        "#model_name = \"small.en\"\n",
        "#model_name = \"medium.en\"\n",
        "model_name = \"large-v2\"\n",
        "\n",
        "output_folder = \"transcriptions\"\n",
        "language = \"english\"\n",
        "export_timestamp_data = True # Outputs timestamp data at the word level if True"
      ],
      "metadata": {
        "id": "LXlOG2HhNSR7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation (run once or after changing `model_name`)"
      ],
      "metadata": {
        "id": "9lWxQykzM4rJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX06OrLFLzBb",
        "outputId": "79c71911-d110-42f6-d9d7-f9bdd45568a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20230314)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (9.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.3.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:54<00:00, 56.7MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# Required third party packages: whisper\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "import whisper\n",
        "import io\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "\n",
        "model = whisper.load_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "fI8zWigLOvTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tip: Upload the file to colab and then right-click to copy the path and paste after running"
      ],
      "metadata": {
        "id": "TUFtC17aSMui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using model: {model_name}\")\n",
        "file_path = input(\"Path to file being transcribed: \")\n",
        "file_path = file_path.strip(\"\\\"\")\n",
        "if not os.path.exists(file_path):\n",
        "\tprint(\"Error getting file\")\n",
        "\texit()\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "\tos.makedirs(output_folder)\n",
        "\tprint(f\"Created output folder {output_folder}.\\n\")\n",
        "\n",
        "# From Whisper API:\n",
        "# Optional text to provide as a prompt for the first window. This can be used to provide, or\n",
        "# \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n",
        "# to make it more likely to predict those word correctly.\n",
        "prompt = input(\"Optional text prompt: \").strip()\n",
        "if prompt == \"\": prompt = None\n",
        "\n",
        "# Get filename stem using pathlib (filename without extension)\n",
        "filename_stem = pathlib.Path(file_path).stem\n",
        "\n",
        "result_fileName = f\"{filename_stem}.txt\"\n",
        "json_fileName = f\"{filename_stem}.json\"\n",
        "\n",
        "start = time.time()\n",
        "result = model.transcribe(audio=file_path, language=language, prompt=prompt)\n",
        "end = time.time()\n",
        "elapsed = float(end - start)\n",
        "\n",
        "# Save transcription text to file\n",
        "print(\"\\nWriting transcription to file...\")\n",
        "with open(os.path.join(output_folder, result_fileName), \"w\", encoding=\"utf-8\") as f:\n",
        "\tf.write(result[\"text\"])\n",
        "\n",
        "# Save the segments data to json file\n",
        "if export_timestamp_data == True:\n",
        "\tprint(\"\\nWriting segment data to file...\")\n",
        "\twith open(os.path.join(output_folder, json_fileName), \"w\", encoding=\"utf-8\") as f:\n",
        "\t\tsegments_data = result[\"segments\"]\n",
        "\t\tjson.dump(segments_data, f, indent=4)\n",
        "\n",
        "elapsed_minutes = str(round(elapsed/60, 2))\n",
        "print(f\"\\nElapsed time With {model_name} Model: {elapsed_minutes} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "aw0XCMP4PMwH",
        "outputId": "67120b6c-cf09-4141-cf2c-65c4d4d480b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model: large-v2\n",
            "Path to file being transcribed: /content/output_podcast.mp3\n",
            "Optional text prompt: \n",
            "\n",
            "Writing transcription to file...\n",
            "\n",
            "Writing segment data to file...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8a15a29179a4>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0melapsedMinutes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nElapsed time With {modelName} Model: {elapsedMinutes} minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'modelName' is not defined"
          ]
        }
      ]
    }
  ]
}